target_dist <- settings$target_dist[i]
iteration <- settings$iteration[i]
seed <- i
set.seed(seed)
#generate data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
#set up variables
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
#update features to include W
feat <- dplyr::select(train_dat, c(W, S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
#include counterfactual covariates (swap control and treatment)
feat_cf <- feat %>%
mutate(W = as.numeric(W == 0))
y <- as.numeric(train_dat$Y)
#run bart
sbart <- dbarts::bart(x.train=as.matrix(feat), y.train=y, x.test=as.matrix(feat_cf), keeptrees=T)
#S-BART credible interval - training - pairwise difference = F
sb_train <- sbart_ci(train_dat, sbart)
#S-BART credible interval - target - pairwise difference = F
sb_target <- sbart_target(K, target_dat, sbart, covars)
#S-BART credible interval - training - pairwise difference = T
sb_train_p <- sbart_ci(train_dat, sbart, pairwise_diff=T)
#S-BART credible interval - target - pairwise difference = T
sb_target_p <- sbart_target(K, target_dat, sbart, covars, pairwise_diff=T)
rm(sbart)
#calculate mean and CIs for individuals and assess accuracy
sb_res <- assess_interval(sb_train, sb_target)
sb_res_p <- assess_interval(sb_train_p, sb_target_p)
#report results
iter_res <- cbind(sb_res, sb_res_p) %>%
data.frame() %>%
rownames_to_column("Metric")
res <- bind_rows(res, iter_res)
}
for (i in 1:2) {
#Setup
moderators <- settings$moderators[i]
covars_fix <- covars[[moderators]]$covars_fix
covars_rand <- covars[[moderators]]$covars_rand
eps_study_m <- covars[[moderators]]$eps_study_m
eps_study_tau <- covars[[moderators]]$eps_study_tau
eps_study_inter <- covars[[moderators]]$eps_study_inter
lin <- covars[[moderators]]$lin
distribution <- settings$distribution[i]
target_dist <- settings$target_dist[i]
iteration <- settings$iteration[i]
seed <- i
set.seed(seed)
#generate data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
#set up variables
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
#update features to include W
feat <- dplyr::select(train_dat, c(W, S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
#include counterfactual covariates (swap control and treatment)
feat_cf <- feat %>%
mutate(W = as.numeric(W == 0))
y <- as.numeric(train_dat$Y)
#run bart
sbart <- dbarts::bart(x.train=as.matrix(feat), y.train=y, x.test=as.matrix(feat_cf), keeptrees=T)
#S-BART credible interval - training - pairwise difference = F
sb_train <- sbart_ci(train_dat, sbart)
#S-BART credible interval - target - pairwise difference = F
sb_target <- sbart_target(K, target_dat, sbart, covars)
#S-BART credible interval - training - pairwise difference = T
sb_train_p <- sbart_ci(train_dat, sbart, pairwise_diff=T)
#S-BART credible interval - target - pairwise difference = T
sb_target_p <- sbart_target(K, target_dat, sbart, covars, pairwise_diff=T)
rm(sbart)
#calculate mean and CIs for individuals and assess accuracy
sb_res <- assess_interval(sb_train, sb_target)
sb_res_p <- assess_interval(sb_train_p, sb_target_p)
#report results
iter_res <- cbind(sb_res, sb_res_p) %>%
data.frame() %>%
rownames_to_column("Metric")
res <- bind_rows(res, iter_res)
}
#run iterations
res <- data.frame()
for (i in 1:2) {
#Setup
moderators <- settings$moderators[i]
covars_fix <- covars[[moderators]]$covars_fix
covars_rand <- covars[[moderators]]$covars_rand
eps_study_m <- covars[[moderators]]$eps_study_m
eps_study_tau <- covars[[moderators]]$eps_study_tau
eps_study_inter <- covars[[moderators]]$eps_study_inter
lin <- covars[[moderators]]$lin
distribution <- settings$distribution[i]
target_dist <- settings$target_dist[i]
iteration <- settings$iteration[i]
seed <- i
set.seed(seed)
#generate data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
#set up variables
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
#update features to include W
feat <- dplyr::select(train_dat, c(W, S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
#include counterfactual covariates (swap control and treatment)
feat_cf <- feat %>%
mutate(W = as.numeric(W == 0))
y <- as.numeric(train_dat$Y)
#run bart
sbart <- dbarts::bart(x.train=as.matrix(feat), y.train=y, x.test=as.matrix(feat_cf), keeptrees=T)
#S-BART credible interval - training - pairwise difference = F
sb_train <- sbart_ci(train_dat, sbart)
#S-BART credible interval - target - pairwise difference = F
sb_target <- sbart_target(K, target_dat, sbart, covars)
#S-BART credible interval - training - pairwise difference = T
sb_train_p <- sbart_ci(train_dat, sbart, pairwise_diff=T)
#S-BART credible interval - target - pairwise difference = T
sb_target_p <- sbart_target(K, target_dat, sbart, covars, pairwise_diff=T)
rm(sbart)
#calculate mean and CIs for individuals and assess accuracy
sb_res <- assess_interval(sb_train, sb_target)
sb_res_p <- assess_interval(sb_train_p, sb_target_p)
#report results
iter_res <- cbind(sb_res, sb_res_p) %>%
data.frame() %>%
rownames_to_column("Metric")
res <- bind_rows(res, iter_res)
}
i=1
#Setup
moderators <- settings$moderators[i]
covars_fix <- covars[[moderators]]$covars_fix
covars_rand <- covars[[moderators]]$covars_rand
moderators
n_sd <- 0
n_target <- 100
honesty <- T
covars_fix <- "age"
covars_rand <- "age"
lin=T
eps_opt <- list(list(eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=0.05),
list(eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05))
settings <- expand.grid(moderators=c(1:2),
distribution = c("same"),
target_dist = c("same"),
iteration = c(1:20))
nrow(settings)
library(tidyverse)
library(dbarts)
source("R/BART.OOSEst.R")
source("R/MDD_Generation_OOSEst.R")
getwd
getwd()
source("R/BART.OOSEst.R")
source("R/BART_OOSEst.R")
source("R/MDD_Generation_OOSEst.R")
source("R/BART_OOSEst.R")
source("R/MDD_Generation_OOSEst.R")
source("R/Comparing_OOSEst.R")
# set up parameters
K <- 10
n_mean <- 200
n_sd <- 0
n_target <- 100
honesty <- T
covars_fix <- "age"
covars_rand <- "age"
lin <- T
distribution <- "same"
target_dist <- "same"
eps_opt <- list(list(eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=0.05),
list(eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05))
settings <- expand.grid(moderators=c(1:2),
iteration = c(1:20))
#run iterations
res <- data.frame()
for (i in 1:2) {
#Setup
moderators <- settings$moderators[i]
eps_study_m <- eps_opt[[moderators]]$eps_study_m
eps_study_tau <- eps_opt[[moderators]]$eps_study_tau
eps_study_inter <- eps_opt[[moderators]]$eps_study_inter
iteration <- settings$iteration[i]
seed <- i
set.seed(seed)
#generate data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
#set up variables
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
#update features to include W
feat <- dplyr::select(train_dat, c(W, S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
#include counterfactual covariates (swap control and treatment)
feat_cf <- feat %>%
mutate(W = as.numeric(W == 0))
y <- as.numeric(train_dat$Y)
#run bart
sbart <- dbarts::bart(x.train=as.matrix(feat), y.train=y, x.test=as.matrix(feat_cf), keeptrees=T)
#S-BART credible interval - training - pairwise difference = F
sb_train <- sbart_ci(train_dat, sbart)
#S-BART credible interval - target - pairwise difference = F
sb_target <- sbart_target(K, target_dat, sbart, covars)
#S-BART credible interval - training - pairwise difference = T
sb_train_p <- sbart_ci(train_dat, sbart, pairwise_diff=T)
#S-BART credible interval - target - pairwise difference = T
sb_target_p <- sbart_target(K, target_dat, sbart, covars, pairwise_diff=T)
rm(sbart)
#calculate mean and CIs for individuals and assess accuracy
sb_res <- assess_interval(sb_train, sb_target)
sb_res_p <- assess_interval(sb_train_p, sb_target_p)
#report results
iter_res <- cbind(sb_res, sb_res_p) %>%
data.frame() %>%
rownames_to_column("Metric")
res <- bind_rows(res, iter_res)
}
View(res)
head(sb_target)
sb_res
#calculate mean and CIs for individuals and assess accuracy
sb_res <- c(assess_interval(sb_train, sb_target),
avg_train_var = mean(sb_train$var),
avg_target_var = mean(sb_target$var))
sb_res_p <- c(assess_interval(sb_train_p, sb_target_p),
avg_train_var = mean(sb_train_p$var),
avg_target_var = mean(sb_target_p$var))
sb_res
sb_res_p
library(tidyverse)
library(dbarts)
source("R/BART_OOSEst.R")
source("R/MDD_Generation_OOSEst.R")
source("R/Comparing_OOSEst.R")
# set up parameters
K <- 10
n_mean <- 200
n_sd <- 0
n_target <- 100
honesty <- T
covars_fix <- "age"
covars_rand <- "age"
lin <- T
distribution <- "same"
target_dist <- "same"
eps_opt <- list(list(eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=0.05),
list(eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05))
settings <- expand.grid(moderators=c(1:2),
iteration = c(1:20))
#run iterations
res <- data.frame()
for (i in 1:nrow(settings)) {
#Setup
moderators <- settings$moderators[i]
eps_study_m <- eps_opt[[moderators]]$eps_study_m
eps_study_tau <- eps_opt[[moderators]]$eps_study_tau
eps_study_inter <- eps_opt[[moderators]]$eps_study_inter
iteration <- settings$iteration[i]
seed <- i
set.seed(seed)
#generate data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
#set up variables
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
#update features to include W
feat <- dplyr::select(train_dat, c(W, S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
#include counterfactual covariates (swap control and treatment)
feat_cf <- feat %>%
mutate(W = as.numeric(W == 0))
y <- as.numeric(train_dat$Y)
#run bart
sbart <- dbarts::bart(x.train=as.matrix(feat), y.train=y, x.test=as.matrix(feat_cf), keeptrees=T)
#S-BART credible interval - training - pairwise difference = F
sb_train <- sbart_ci(train_dat, sbart)
#S-BART credible interval - target - pairwise difference = F
sb_target <- sbart_target(K, target_dat, sbart, covars)
#S-BART credible interval - training - pairwise difference = T
sb_train_p <- sbart_ci(train_dat, sbart, pairwise_diff=T)
#S-BART credible interval - target - pairwise difference = T
sb_target_p <- sbart_target(K, target_dat, sbart, covars, pairwise_diff=T)
rm(sbart)
#calculate mean and CIs for individuals and assess accuracy
sb_res <- c(assess_interval(sb_train, sb_target),
avg_train_var = mean(sb_train$var),
avg_target_var = mean(sb_target$var))
sb_res_p <- c(assess_interval(sb_train_p, sb_target_p),
avg_train_var = mean(sb_train_p$var),
avg_target_var = mean(sb_target_p$var))
#report results
iter_res <- cbind(sb_res, sb_res_p) %>%
data.frame() %>%
rownames_to_column("Metric")
res <- bind_rows(res, iter_res)
}
View(res)
saveRDS(res, "BART_vartest.RDS")
#mse - should always be equal
mse <- filter(res, grepl("mse", Metric)==T)
mse
sum(round(mse$sb_res, 10) != round(mse$sb_res_p, 10))
#coverage - want close to 95%
res %>%
pivot_longer(cols=c(sb_res, sb_res_p))
#coverage - want close to 95%
res %>%
filter(grepl("coverage", Metric)==T) %>%
pivot_longer(cols=c(sb_res, sb_res_p), names_to = "Method", values_to = "Coverage")
#coverage - want close to 95%
res %>%
filter(grepl("coverage", Metric)==T) %>%
pivot_longer(cols=c(sb_res, sb_res_p), names_to = "Method", values_to = "Coverage") %>%
ggplot(aes(x=Metric, color=Method, y=Coverage)) +
geom_boxplot()
#variance
res %>%
filter(grepl("var", Metric)==T) %>%
pivot_longer(cols=c(sb_res, sb_res_p), names_to = "Method", values_to = "Variance") %>%
ggplot(aes(x=Metric, color=Method, y=Variance)) +
geom_boxplot()
#variance
res %>%
filter(grepl("var", Metric)==T) %>%
pivot_longer(cols=c(sb_res, sb_res_p), names_to = "Method", values_to = "Variance") %>%
ggplot(aes(x=Method, y=Variance)) +
geom_boxplot() +
facet_wrap(~Metric, scales = "free")
names(res)
#check results
#View(res)
colnames(res) <- c("Metric", "S_NonPair", "S_Pair")
#mse - should always be equal
mse <- filter(res, grepl("mse", Metric)==T)
sum(round(mse$sb_res, 10) != round(mse$sb_res_p, 10)) #0 is what we want to see
sum(round(mse$S_NonPair, 10) != round(mse$S_Pair, 10)) #0 is what we want to see
#coverage - want close to 95%
res %>%
filter(grepl("coverage", Metric)==T) %>%
pivot_longer(cols=c(sb_res, sb_res_p), names_to = "Method", values_to = "Coverage") %>%
ggplot(aes(x=Metric, color=Method, y=Coverage)) +
geom_boxplot()
#coverage - want close to 95%
res %>%
filter(grepl("coverage", Metric)==T) %>%
pivot_longer(cols=c(S_NonPair, S_Pair), names_to = "Method", values_to = "Coverage") %>%
ggplot(aes(x=Metric, color=Method, y=Coverage)) +
geom_boxplot()
#variance
res %>%
filter(grepl("var", Metric)==T) %>%
pivot_longer(cols=c(S_NonPair, S_Pair), names_to = "Method", values_to = "Variance") %>%
ggplot(aes(x=Method, y=Variance)) +
geom_boxplot() +
facet_wrap(~Metric, scales = "free")
1-.78
.977-.642
.944-.58
.868-.465
.783-.350
.783-.360
.589-.173
.479-.092
.358-.023
1-.707
.977-.637
.942-.564
.899-.481
.785-.469
.75-.326
library(tidyverse)
library(lme4)
library(rsample)
library(multcomp)
library(MASS)
library(grf)
library(dbarts)
source("R/MDD_Generation_OOSEst.R")
source("R/MA_OOSEst.R")
source("R/Bootstrap_OOSEst.R")
source("R/BART_OOSEst.R")
source("R/Comparing_OOSEst.R")
# set up parameters
K <- 10
n_mean <- 500
n_sd <- 0
n_target <- 100
honesty <- T
mods <- list(list(covars_fix="age", covars_rand="age", lin=T,
eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=T,
eps_study_m=1, eps_study_tau=0.05, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=T,
eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=T,
eps_study_m=1, eps_study_tau=1, eps_study_inter=0.5),
list(covars_fix=c("age", "madrs"), covars_rand=c("age", "madrs"),
lin=T, eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=c(0.05,0.05)),
list(covars_fix=c("age", "madrs"), covars_rand=c("age", "madrs"),
lin=T, eps_study_m=1, eps_study_tau=0.5, eps_study_inter=c(0.5,0.05)),
list(covars_fix=c("age2", "sex"), covars_rand=c("age2"),
lin=T, eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05),
list(covars_fix=c("age2", "sex"), covars_rand=c("age2"),
lin=T, eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.5),
list(covars_fix="age", covars_rand="age", lin=F,
eps_study_m=0.05, eps_study_tau=0.05, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=F,
eps_study_m=1, eps_study_tau=0.05, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=F,
eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.05),
list(covars_fix="age", covars_rand="age", lin=F,
eps_study_m=1, eps_study_tau=0.5, eps_study_inter=0.5))
settings <- expand.grid(moderators = c(1:length(mods)),
distribution = c("same", "varying_madrs", "separate_age"),
target_dist = c("same", "different"),
iteration = c(1:100))
i=8
moderators <- settings$moderators[i]
covars_fix <- mods[[moderators]]$covars_fix
covars_rand <- mods[[moderators]]$covars_rand
eps_study_m <- mods[[moderators]]$eps_study_m
eps_study_tau <- mods[[moderators]]$eps_study_tau
eps_study_inter <- mods[[moderators]]$eps_study_inter
lin <- mods[[moderators]]$lin
distribution <- settings$distribution[i]
target_dist <- settings$target_dist[i]
iteration <- settings$iteration[i]
seed <- i
#run main function
set.seed(seed)
## Simulate training and target (OOS) data
sim_dat <- gen_mdd(K, n_mean, n_sd, n_target, covars_fix, covars_rand, lin,
eps_study_m, eps_study_tau, eps_study_inter,
distribution, target_dist)
train_dat <- sim_dat[["train_dat"]]
target_dat <- sim_dat[["target_dat"]]
## Mixed effects model: Correct
#change for scenario with age^2
if ("age2" %in% covars_fix) {
main_eff <- "Y ~ madrs + sex + age2 + W + "
} else {
main_eff <- "Y ~ madrs + sex + age + W + "
}
formula <- as.formula(paste0(main_eff,
paste("W", covars_fix, sep=":", collapse=" + "),
" + (W + ",
paste("W", covars_rand, sep=":", collapse=" + "),
" | S)"))
## Causal Forest
if ("age2" %in% covars_fix) {
covars <- c("sex", "smstat", "weight", "age2", "madrs")
} else {
covars <- c("sex", "smstat", "weight", "age", "madrs")
}
feat <- dplyr::select(train_dat, c(S, all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
tau_forest <- grf::causal_forest(X=feat, Y=train_dat$Y, W=train_dat$W,
num.threads=3, honesty=T, num.trees=1000)
tau_hat <- predict(tau_forest, estimate.variance=T)
#causal forest CI - training
cf_train <- cf_ci(train_dat, tau_hat)
#causal forest CI - target
cf_target <- impute_rand(1000, K, target_dat, tau_forest, covars)
#calculate mean and CIs for individuals and assess accuracy
cf_res <- assess_interval(cf_train, cf_target)
View(cf_target)
sum(cf_target$tau <= cf_target$q97.5 & cf_target$tau >= cf_target$q2.5)
sum(cf_target$tau <= cf_target$upper & cf_target$tau >= cf_target$lower)
mean(cf_target$q97.5-cf_target$q2.5)
mean(cf_target$upper-cf_target$lower)
mean((cf_target$q97.5-cf_target$q2.5)/cf_target$sd)
mean((cf_target$upper-cf_target$lower)/cf_target$sd)
mean((cf_target$q97.5-cf_target$q2.5)/cf_target$sd)/2
mods
mods[i]
