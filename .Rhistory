select(-c(W, m, tau, eps, Y))
head(new_mem)
head(new_feat)
#predict CATE
new_mem$tau_hat <- predict(tau_forest, newdata = new_feat)$predictions
#create confidence intervals
cis <- new_mem %>%
group_by(sex, smstat, weight, age, madrs, tau) %>%
summarise(mean = mean(tau_hat),
sd = sd(tau_hat)) %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
cis
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
mse
ci_coverage
ci_length
#default method: https://grf-labs.github.io/grf/REFERENCE.html#missing-values
#assign study
#we don't need to replicate because we will get the same prediction each time
new_default <- test_dat %>%
mutate(S = factor(NA, levels=1:10)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T, ignore_na = T)
head(new_default)
K
#default method: https://grf-labs.github.io/grf/REFERENCE.html#missing-values
#assign study
#we don't need to replicate because we will get the same prediction each time
new_default <- test_dat %>%
mutate(S = factor(NA, levels=1:K)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T, ignore_na = T)
head(new_default)
#predict CATE
cate_default <- predict(tau_forest, newdata = new_default, estimate.variance = T)
new_feat <- new_default %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
cate_default <- predict(tau_forest, newdata = new_default, estimate.variance = T)
ncol(feat)
head(feat)
head(new_feat)
#predict CATE
cate_default <- predict(tau_forest, newdata = new_feat, estimate.variance = T)
head(cate_default)
head(new_default)
new_default$mean <- cate_default$predictions
new_default$sd <- sqrt(cate_default$variance.estimates)
#create confidence intervals
cis <- new_default %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
head(cis)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
mse
ci_coverage
ci_length
?list
impute_rand <- function(N, test_dat, tau_forest) {
#assign study
new_dat <- test_dat %>%
slice(rep(1:n(), each=N)) %>%
mutate(S = sample(1:K, nrow(test_dat)*N, replace = T)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
new_feat <- new_dat %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
new_dat$tau_hat <- predict(tau_forest, newdata = new_feat)$predictions
#create confidence intervals
cis <- new_dat %>%
group_by(sex, smstat, weight, age, madrs, tau) %>%
summarise(mean = mean(tau_hat),
sd = sd(tau_hat)) %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
impute_mem <- function(N, train_dat, test_dat, tau_forest) {
#create membership model
mem_mod <- multinom(S ~ sex + smstat + weight + age + madrs + Y, data=train_dat)
#summary(mem_mod)
#round(fitted(mem_mod), 2) #looks at probabilities in each class
#preds <- predict(mem_mod, newdata = train_dat, "class")
#tab <- table(train_dat$S, preds); #round((sum(diag(tab))/sum(tab))*100,2)
#define probabilities
mem_probs <- predict(mem_mod, newdata = test_dat, type = "probs")
S_mem <- c()
for (i in 1:nrow(mem_probs)) {
S_mem <- c(S_mem, sample(1:K, N, replace=T, prob=mem_probs[i,]))
}
#assign study
new_mem <- test_dat %>%
slice(rep(1:n(), each=N)) %>%
mutate(S = S_mem) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
new_feat <- new_mem %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
new_mem$tau_hat <- predict(tau_forest, newdata = new_feat)$predictions
#create confidence intervals
cis <- new_mem %>%
group_by(sex, smstat, weight, age, madrs, tau) %>%
summarise(mean = mean(tau_hat),
sd = sd(tau_hat)) %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
impute_default <- function(K, test_dat, tau_forest) {
#default method: https://grf-labs.github.io/grf/REFERENCE.html#missing-values
#assign study
#we don't need to replicate because we will get the same prediction each time
new_default <- test_dat %>%
mutate(S = factor(NA, levels=1:K)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T, ignore_na = T)
new_feat <- new_default %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
cate_default <- predict(tau_forest, newdata = new_feat, estimate.variance = T)
new_default$mean <- cate_default$predictions
new_default$sd <- sqrt(cate_default$variance.estimates)
#create confidence intervals
cis <- new_default %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
## FUNCTION
N <- 100
test_dat <- expand.grid(W = c(0, 1),
sex = c(0, 1),
smstat = c(0, 1),
weight = seq(45, 130, by=10),
age = seq(18, 75, by=10),
madrs = seq(20, 50, by=5))
compare_oos <- function(N=100, K=6, n_mean=200, n_sd=0, scenario="1a",
distribution="same", test_dat, test_scenario="random") {
## Simulate training and testing (OOS) data
sim_dat <- gen_mdd(K, n_mean, n_sd, scenario, distribution, test_dat, test_scenario)
train_dat <- sim_dat[["train_dat"]]
test_dat <- sim_dat[["test_dat"]]
covars <- c("sex", "smstat", "weight", "age", "madrs")
feat <- select(train_dat, c(S,all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
tau_true <- train_dat$tau
## Fit models (for now, causal forest with pooling with trial indicator)
tau_forest <- causal_forest(X=feat, Y=train_dat$Y, W=train_dat$W,
num.threads=3, honesty=F, num.trees=1000)
tau_hat <- predict(tau_forest, estimate.variance=T)
#mse for training data
train_mse <- mean((tau_hat$predictions - tau_true)^2)
#CI coverage for training data
sd <- sqrt(tau_hat$variance.estimates)
lower <- tau_hat$predictions + qt(.025, df=nrow(train_dat)-1)*sd
upper <- tau_hat$predictions + qt(.975, df=nrow(train_dat)-1)*sd
train_coverage <- sum(ifelse(tau_true >= lower & tau_true <= upper, 1, 0))/nrow(train_dat)
train_res <- c(train_mse=train_mse, train_coverage=train_coverage)
## Calculate mean and CIs for each test individual according to each imputation method
#random
res_rand <- impute_rand(N, test_dat, tau_forest)
#study membership model
res_mem <- impute_mem(N, train_dat, test_dat, tau_forest)
#within-forest default
res_default <- impute_default(K, test_dat, tau_forest)
## Save results
return(list(train_res=train_res, res_rand=res_rand,
res_mem=res_mem, res_default=res_default))
}
#interior function
add_agemadrs <- function(dat, n, k, distribution) {
#add age and madrs
if (distribution == "same") {
dat <- dat %>%
mutate(age = rtruncnorm(n=n, a=18, b=75, mean=45, sd=10),
madrs = rtruncnorm(n=n, a=26, b=60, mean=31, sd=4.1))
} else if (distribution == "varying_madrs") {
dat <- dat %>%
mutate(age = rtruncnorm(n=n, a=18, b=75, mean=45, sd=10),
madrs = rtruncnorm(n=n, a=26-k*1.5, b=60-k*1.5, mean=31-k*1.5, sd=4.1))
} else if (distribution == "halfdiff_madrsage") {
if (k%%2 == 0 ) {
dat <- dat %>%
mutate(age = rtruncnorm(n=n, a=30, b=75, mean=50, sd=10),
madrs = rtruncnorm(n=n, a=30, b=60, mean=40, sd=4.1))
} else {
dat <- dat %>%
mutate(age = rtruncnorm(n=n, a=18, b=75, mean=45, sd=10),
madrs = rtruncnorm(n=n, a=26, b=60, mean=31, sd=4.1))
}
} else if (distribution == "separate_age") {
ages <- seq(18,75,by=(75-18)/10)
dat <- dat %>%
mutate(age = runif(n=n, min=ages[k], max=ages[k+1]),
madrs = rtruncnorm(n=n, a=26, b=60, mean=31, sd=4.1))
}
return(dat)
}
#main function
gen_mdd <- function (K=6, n_mean=200, n_sd=0, scenario="1a",
distribution="same", test_dat, test_scenario="random") {
train_dat <- data.frame()
n_study <- floor(rnorm(K, mean=n_mean, sd=n_sd))
for (k in 1:K) {
n <- n_study[k]
#sample covariates
dat <- data.frame(
#age = rtruncnorm(n=n, a=18, b=75, mean=45, sd=10),
sex = rbinom(n=n, size=1, prob=.65),
smstat = rbinom(n=n, size=1, prob=.3),
weight = rtruncnorm(n=n, a=45, b=140, mean=80, sd=15),
#madrs = rtruncnorm(n=n, a=26, b=60, mean=31, sd=4.1),
W = rbinom(n=n, size=1, prob=.5),
S = rep(k, n),
id = seq(1, n),
eps = rnorm(n, mean=0, sd=.05)
)
dat <- add_agemadrs(dat, n, k, distribution) %>%
mutate(weight = round(weight, 2),
age = round(age, 2),
madrs = round(madrs, 0))
train_dat <- bind_rows(train_dat, dat)
}
#tau and Y
if (scenario == "1a") {
study_main <- runif(K, min=-14, max=-7)
study_inter <- runif(K, min=0.1, max=0.5)
study_tau <- runif(K, min=2.5, max=3.5)
train_dat <- train_dat %>%
mutate(study_main = study_main[S],
study_inter = study_inter[S],
study_tau = study_tau[S],
m = 10.7 - study_main - 0.02*age - 0.87*madrs -
0.15*sex + study_inter*madrs,
tau = -8.5 + 0.07*age + 0.20*madrs + study_tau) %>%
select(-study_main, -study_inter, -study_tau)
if (test_scenario == "random") {
test_main <- runif(1, min=-14, max=-7)
test_inter <- runif(1, min=0.1, max=0.5)
test_tau <- runif(1, min=2.5, max=3.5)
test_dat <- test_dat %>%
mutate(test_main = test_main + rnorm(nrow(test_dat), mean=0, sd=0.1),
test_inter = test_inter + rnorm(nrow(test_dat), mean=0, sd=0.1),
test_tau = test_tau + rnorm(nrow(test_dat), mean=0, sd=0.1),
m = 10.7 - test_main - 0.02*age - 0.87*madrs -
0.15*sex + test_inter*madrs,
tau = -8.5 + 0.07*age + 0.20*madrs + test_tau) %>%
select(-test_main, -test_inter, -test_tau)
} #else if (test_scenario == "unobs_confounder") {
#}
}
if (scenario == "1b") {
study_tau <- runif(K, min=2.5, max=3.5)
train_dat <- train_dat %>%
mutate(study_tau = study_tau[S],
m = 0,
tau = (study_tau/(1+exp(-1/12*age)))*(study_tau/(1+exp(-12*madrs)))) %>%
select(-study_tau)
if (test_scenario == "random") {
test_tau <- runif(1, min=2.5, max=3.5)
test_dat <- test_dat %>%
mutate(test_tau = test_tau + rnorm(nrow(test_dat), mean=0, sd=0.1),
m = 0,
tau = (test_tau/(1+exp(-1/12*age)))*(test_tau/(1+exp(-12*madrs)))) %>%
select(-test_tau)
} #else if (test_scenario == "unobs_confounder") {
#}
}
train_dat <- train_dat %>%
mutate(Y = m + W*tau + eps) %>%
select(-c(eps, m)) %>%
mutate(S = factor(S)) %>%
relocate(S, id, W, sex, smstat, weight, age, madrs, Y, tau)
test_dat <- test_dat %>%
mutate(eps = rnorm(nrow(test_dat), mean=0, sd=0.05),
Y = m + W*tau + eps)
return(list(train_dat=train_dat, test_dat=test_dat))
}
a <- compare_oos()
a <- compare_oos(test_dat=test_dat)
a
a$res_rand$cis %>% View()
a$res_mem$cis %>% View()
a$res_default$cis %>% View()
View(cbind(a$res_rand$cis$mean, a$res_mem$cis$mean, a$res_default$cis$mean))
## FUNCTION
N <- 100
test_dat <- expand.grid(W = c(0, 1),
sex = c(0, 1),
smstat = c(0, 1),
weight = seq(45, 130, by=10),
age = seq(18, 75, by=10),
madrs = seq(20, 50, by=5))
N=100
K=6
## Simulate training and testing (OOS) data
sim_dat <- gen_mdd(K, n_mean, n_sd, scenario, distribution, test_dat, test_scenario)
train_dat <- sim_dat[["train_dat"]]
test_dat <- sim_dat[["test_dat"]]
covars <- c("sex", "smstat", "weight", "age", "madrs")
feat <- select(train_dat, c(S,all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
tau_true <- train_dat$tau
## Fit models (for now, causal forest with pooling with trial indicator)
tau_forest <- causal_forest(X=feat, Y=train_dat$Y, W=train_dat$W,
num.threads=3, honesty=F, num.trees=1000)
tau_forest
class(tau_forest)
tau_forest$`_root_nodes`
tau_forest$`_send_missing_left`
tau_forest$`_pv_values`
# set up data
N <- 100
K <- 6
n_sd <- 0
test_dat <- expand.grid(W = c(0, 1),
sex = c(0, 1),
smstat = c(0, 1),
weight = seq(45, 130, by=10),
age = seq(18, 75, by=10),
madrs = seq(20, 50, by=5))
settings <- expand.grid(n_mean = c(200, 500),
scenario = c("linear", "nonlinear"),
distribution = c("same", "varying_madrs",
"halfdiff_madrsage", "separate_age"),
test_scenario = c("random"))
settings
settings <- expand.grid(n_mean = c(200, 500),
scenario = c("linear", "nonlinear"),
distribution = c("same", "varying_madrs",
"halfdiff_madrsage", "separate_age"),
test_scenario = c("random"),
iteration = c(1:500))
nrow(settings)
nrow(settings)/16
View(settings)
paste(paste("results",seed,N,K,n_mean,n_sd,scenario,distribution,test_scenario,
sep = "_"),".Rdata",sep="")
seed=1
paste(paste("results",seed,N,K,n_mean,n_sd,scenario,distribution,test_scenario,
sep = "_"),".Rdata",sep="")
library(tidyverse)
library(rsample)
library(grf)
library(fastDummies)
library(nnet)
#source("Comparing_methods_functions.R")
source("MDD_Simulation_OOSEst.R")
impute_rand <- function(N, test_dat, tau_forest) {
#assign study
new_dat <- test_dat %>%
slice(rep(1:n(), each=N)) %>%
mutate(S = sample(1:K, nrow(test_dat)*N, replace = T)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
new_feat <- new_dat %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
new_dat$tau_hat <- predict(tau_forest, newdata = new_feat)$predictions
#create confidence intervals
cis <- new_dat %>%
group_by(sex, smstat, weight, age, madrs, tau) %>%
summarise(mean = mean(tau_hat),
sd = sd(tau_hat)) %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
impute_mem <- function(N, train_dat, test_dat, tau_forest) {
#create membership model
mem_mod <- multinom(S ~ sex + smstat + weight + age + madrs + Y, data=train_dat)
#summary(mem_mod)
#round(fitted(mem_mod), 2) #looks at probabilities in each class
#preds <- predict(mem_mod, newdata = train_dat, "class")
#tab <- table(train_dat$S, preds); #round((sum(diag(tab))/sum(tab))*100,2)
#define probabilities
mem_probs <- predict(mem_mod, newdata = test_dat, type = "probs")
S_mem <- c()
for (i in 1:nrow(mem_probs)) {
S_mem <- c(S_mem, sample(1:K, N, replace=T, prob=mem_probs[i,]))
}
#assign study
new_mem <- test_dat %>%
slice(rep(1:n(), each=N)) %>%
mutate(S = S_mem) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
new_feat <- new_mem %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
new_mem$tau_hat <- predict(tau_forest, newdata = new_feat)$predictions
#create confidence intervals
cis <- new_mem %>%
group_by(sex, smstat, weight, age, madrs, tau) %>%
summarise(mean = mean(tau_hat),
sd = sd(tau_hat)) %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
impute_default <- function(K, test_dat, tau_forest) {
#default method: https://grf-labs.github.io/grf/REFERENCE.html#missing-values
#assign study
#we don't need to replicate because we will get the same prediction each time
new_default <- test_dat %>%
mutate(S = factor(NA, levels=1:K)) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T, ignore_na = T)
new_feat <- new_default %>%
select(-c(W, m, tau, eps, Y))
#predict CATE
cate_default <- predict(tau_forest, newdata = new_feat, estimate.variance = T)
new_default$mean <- cate_default$predictions
new_default$sd <- sqrt(cate_default$variance.estimates)
#create confidence intervals
cis <- new_default %>%
mutate(lower = mean + qt(.025, df=N-1)*sd,
upper = mean + qt(.975, df=N-1)*sd)
#calculate accuracy
mse <- mean((cis$mean - cis$tau)^2)
ci_coverage <- sum(ifelse(cis$tau >= cis$lower & cis$tau <= cis$upper, 1, 0))/nrow(cis)
ci_length <- mean(cis$upper - cis$lower)
return(list(mse=mse, ci_coverage=ci_coverage, ci_length=ci_length, cis=cis))
}
compare_oos <- function(N=100, K=6, n_mean=200, n_sd=0, scenario="linear",
distribution="same", test_dat, test_scenario="random") {
## Simulate training and testing (OOS) data
sim_dat <- gen_mdd(K, n_mean, n_sd, scenario, distribution, test_dat, test_scenario)
train_dat <- sim_dat[["train_dat"]]
test_dat <- sim_dat[["test_dat"]]
covars <- c("sex", "smstat", "weight", "age", "madrs")
feat <- select(train_dat, c(S,all_of(covars))) %>%
fastDummies::dummy_cols(select_columns="S", remove_selected_columns=T)
tau_true <- train_dat$tau
## Fit models (for now, causal forest with pooling with trial indicator)
tau_forest <- causal_forest(X=feat, Y=train_dat$Y, W=train_dat$W,
num.threads=3, honesty=F, num.trees=1000)
tau_hat <- predict(tau_forest, estimate.variance=T)
#mse for training data
train_mse <- mean((tau_hat$predictions - tau_true)^2)
#CI coverage for training data
sd <- sqrt(tau_hat$variance.estimates)
lower <- tau_hat$predictions + qt(.025, df=nrow(train_dat)-1)*sd
upper <- tau_hat$predictions + qt(.975, df=nrow(train_dat)-1)*sd
train_coverage <- sum(ifelse(tau_true >= lower & tau_true <= upper, 1, 0))/nrow(train_dat)
train_res <- c(train_mse=train_mse, train_coverage=train_coverage)
## Calculate mean and CIs for each test individual according to each imputation method
#random
res_rand <- impute_rand(N, test_dat, tau_forest)
#study membership model
res_mem <- impute_mem(N, train_dat, test_dat, tau_forest)
#within-forest default
res_default <- impute_default(K, test_dat, tau_forest)
## Save results
return(list(train_res=train_res, res_rand=res_rand,
res_mem=res_mem, res_default=res_default,
N=N, K=K, n_mean=n_mean, n_sd=n_sd,
scenario=scenario, distribution=distribution,
test_dat=test_dat, test_scenario=test_scenario))
}
# set up data
N <- 100
K <- 6
n_sd <- 0
test_dat <- expand.grid(W = c(0, 1),
sex = c(0, 1),
smstat = c(0, 1),
weight = seq(45, 130, by=10),
age = seq(18, 75, by=10),
madrs = seq(20, 50, by=5))
settings <- expand.grid(n_mean = c(200, 500),
scenario = c("linear", "nonlinear"),
distribution = c("same", "varying_madrs",
"halfdiff_madrsage", "separate_age"),
test_scenario = c("random"),
iteration = c(1:500))
#sets the row of the settings that you will use
i=as.numeric(Sys.getenv('SGE_TASK_ID'))
i
i=1
n_mean <- settings$n_mean[i]
scenario <- settings$scenario[i]
distribution <- settings$distribution[i]
test_scenario <- settings$test_scenario[i]
iteration <- settings$iteration[i]
seed <- i
#now code
set.seed(seed)
results <- compare_oos(N=N, K=K, n_mean=n_mean, n_sd=n_sd, scenario=scenario,
distribution=distribution, test_dat=test_dat, test_scenario=test_scenario)
results
